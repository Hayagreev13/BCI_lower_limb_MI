{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.9.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaya\\anaconda3\\lib\\site-packages\\pyglet\\media\\codecs\\wmf.py:838: UserWarning: [WinError -2147417850] Cannot change thread mode after it is set\n",
      "  warnings.warn(str(err))\n"
     ]
    }
   ],
   "source": [
    "# code for storing subject and trial info\n",
    "from psychopy import gui, visual, core, data, event, logging, clock, colors, layout\n",
    "# GUI for saving data # Store info about the experiment session\n",
    "expName = 'game'\n",
    "exType = 'wet'\n",
    "expInfo = {'participant': 'X02','type': exType, 'expName' : expName}\n",
    "# dlg = gui.DlgFromDict(dictionary=expInfo, sortKeys=False, title=expName)\n",
    "# if dlg.OK == False:\n",
    "#     core.quit()  # user pressed cancel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import src.realtime_utils as utils\n",
    "import torch\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "#INIT\n",
    "filt_ord = 2\n",
    "freq_limits = np.asarray([[1,100]]) \n",
    "freq_limits_names = ['1_100Hz']\n",
    "sample_duration = 125\n",
    "sampling_frequency = 250\n",
    "electrode_names =  ['FZ', 'C3', 'CZ', 'C4', 'PZ', 'PO7', 'OZ', 'PO8']\n",
    "filters = utils.init_filters(freq_limits, sampling_frequency, filt_type = 'bandpass', order=filt_ord)\n",
    "segments, labels, predictions = [], [], []\n",
    "total_outlier = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureExtractor(\n",
       "  (temporal): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(1, 64), stride=(1, 1), padding=same, bias=False)\n",
       "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (spatial): Sequential(\n",
       "    (0): Conv2d(8, 16, kernel_size=(8, 1), stride=(1, 1), groups=8, bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (seperable): Sequential(\n",
       "    (0): Conv2d(16, 16, kernel_size=(1, 16), stride=(1, 1), padding=same, groups=16, bias=False)\n",
       "    (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (avgpool1): AvgPool2d(kernel_size=[1, 4], stride=[1, 4], padding=0)\n",
       "  (avgpool2): AvgPool2d(kernel_size=[1, 8], stride=[1, 8], padding=0)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (view): Sequential(\n",
       "    (0): Flatten()\n",
       "  )\n",
       "  (fc2): Linear(in_features=240, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init DL model\n",
    "subject = expInfo['participant']\n",
    "net = utils.FeatureExtractor()\n",
    "path = Path(f'./models/{subject}_metamodel.pth')\n",
    "pretrained_dict = torch.load(path)\n",
    "net.load_state_dict(pretrained_dict)\n",
    "net = net.float()\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynput.keyboard import Key, Controller\n",
    "keyboard_game = Controller()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conducting game experiment for subject : X02\n",
      "No. of Practice Trials before : 2\n",
      "Trial Number : 04\n",
      "Actual Trial\n",
      "Total number of trials as of now : 6\n",
      "Saving file as ..  X02_2022-06-23_game_wet_04.csv\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaya\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:443: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Convolution.cpp:744.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "prediction: 1\n",
      "prediction: 0\n",
      "prediction: 1\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "#psychopy libraries for running the visual cues\n",
    "from psychopy import gui, visual, core, data, event, logging, clock, colors, layout\n",
    "import psychopy.iohub as io\n",
    "from psychopy.hardware import keyboard\n",
    "#numpy and pd for data storing and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import  shuffle\n",
    "# misc libraries to structure the cues properly and save it with date time and stuff\n",
    "import time\n",
    "from datetime import date\n",
    "from pathlib import Path\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import msvcrt\n",
    "import datetime\n",
    "# lab streaming layer library to capture the data sent by unicorn EEG headset\n",
    "from pylsl import StreamInlet, resolve_stream\n",
    "\n",
    "#change path of folders according to your needs\n",
    "# Data file name stem = absolute path + name; later add .psyexp, .csv, .log, etc\n",
    "\n",
    "result_path = Path(f'./Expdata/Subjects/'+exType+'/'+expInfo['participant']+'/'+expName+'/')\n",
    "result_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "columns=['Time','FZ', 'C3', 'CZ', 'C4', 'PZ', 'PO7', 'OZ', 'PO8','AccX','AccY','AccZ','Gyro1','Gyro2','Gyro3',\n",
    "                                  'Battery','Counter','Validation']\n",
    "\n",
    "data_dict = dict((k, []) for k in columns)\n",
    "current_seg = pd.DataFrame()\n",
    "total_MI_outliers = 0\n",
    "all_MI_segments, all_MI_labels, predictions = [], [], []\n",
    "\n",
    "MI_dict = {'MI_segments' : [], 'predictions': []}\n",
    "\n",
    "# below code is for initializing the streaming layer which will help us capture data later\n",
    "finished = False\n",
    "streams = resolve_stream()\n",
    "inlet = StreamInlet(streams[0])\n",
    "\n",
    "# Auto updating trial numbers\n",
    "trial_list = []\n",
    "for instance in os.scandir(result_path):\n",
    "        if instance.path.endswith('.csv'):\n",
    "            length = len(instance.path)\n",
    "            trial_list.append(int(instance.path[length-5]))\n",
    "\n",
    "if len(trial_list) == 0:\n",
    "    session = '01'\n",
    "elif len(trial_list) < 9 :\n",
    "    session = len(trial_list) + 1\n",
    "    session = '0' + str(session)\n",
    "else :\n",
    "    session = str(len(trial_list) + 1)\n",
    "\n",
    "print(f\"Conducting {expName} experiment for subject :\", expInfo['participant'])\n",
    "print('No. of Practice Trials before :', 2)\n",
    "print(\"Trial Number :\", session)\n",
    "\n",
    "print('Actual Trial')\n",
    "print('Total number of trials as of now :', int(session) + 2)\n",
    "results_fname = expInfo['participant']+'_'+str(date.today())+'_'+expName+'_'+ expInfo['type']+'_'+session+'.csv'\n",
    "print(\"Saving file as .. \", results_fname)\n",
    "\n",
    "\n",
    "Fs = 250 # sampling frequency of Unicorn EEG cap\n",
    "temp = []\n",
    "pred =1\n",
    "pred1 = 1\n",
    "initial = 0\n",
    "final = 125\n",
    "prediction = -1\n",
    "outliers = []\n",
    "key = False\n",
    "while not finished:\n",
    "\n",
    "    sample, timestamp = inlet.pull_sample()\n",
    "    \n",
    "    res = [timestamp] + sample \n",
    "    data_dict = utils.update_data(data_dict,res)\n",
    "\n",
    "    if len(data_dict['FZ']) % 125 == 0:\n",
    "        df, initial, final = utils.segment_dict(initial, final, sample_duration, data_dict)\n",
    "        segment_filt, out, filters = utils.pre_processing(df, electrode_names, filters, \n",
    "                        sample_duration, freq_limits_names, sampling_frequency)\n",
    "        current_seg = utils.concatdata(current_seg,segment_filt)   \n",
    "        outliers.append(out)   \n",
    "        # do prediction with current segment and update number\n",
    "        if current_seg.shape[1] == 500:\n",
    "            if sum(outliers) > 0:\n",
    "                total_MI_outliers +=1\n",
    "                print('OUTLIER')\n",
    "                if key:\n",
    "                    keyboard_game.release(key) \n",
    "            else:\n",
    "                all_MI_segments.append(current_seg)\n",
    "                prediction = utils.do_prediction(current_seg, net)\n",
    "                predictions.append(int(prediction[0]))\n",
    "                print(f\"prediction: {prediction[0]}\") \n",
    "                if key:\n",
    "                    keyboard_game.release(key)\n",
    "\n",
    "                if prediction[0] ==0:\n",
    "                    key = Key.up\n",
    "                    keyboard_game.press(key)\n",
    "                elif prediction[0] ==1:\n",
    "                    key = Key.down\n",
    "                    keyboard_game.press(key)\n",
    "\n",
    "#                 if prediction[0] == 0 and pred == 0 and pred1 == 0:\n",
    "#                     continue\n",
    "#                 if prediction[0] == 0:\n",
    "#                     key = Key.up\n",
    "#                     keyboard_game.press(key)\n",
    "#                 elif prediction[0] == 1:\n",
    "#                     key = Key.up\n",
    "#                     keyboard_game.press(key)\n",
    "#             pred = prediction[0]\n",
    "#             pred1 = prediction[0]\n",
    "            outliers = outliers[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making dictionary into a dataframe for saving it as csv\n",
    "record_data = pd.DataFrame.from_dict(data_dict)\n",
    "\n",
    "#saving MI segments in pickle file\n",
    "MI_dict = {'MI_segments' : [], 'predictions': []}\n",
    "MI_dict['MI_segments'] = all_MI_segments\n",
    "MI_dict['predictions'] = predictions\n",
    "#f'{subject}_{str(date.today())}_{expName}_{exp_type}_{session}_MIData.pkl'\n",
    "result_path = Path(f'./Expdata/Subjects/{exType}/{subject}/{expName}')\n",
    "exp_type = expInfo['type']\n",
    "MI_fname = f'{subject}_{str(date.today())}_{expName}_{exp_type}_{session}_MIData.pkl'\n",
    "print(\"Saving file MI Data file as .. \", MI_fname)\n",
    "save_file = open(result_path / MI_fname, \"wb\")\n",
    "pickle.dump(MI_dict, save_file)\n",
    "save_file.close()\n",
    "\n",
    "#fname = Path('./Expdata/Subjects/'+expInfo['participant']+'/'+ expName + '/'+results_fname)\n",
    "fname = Path('./Expdata/Subjects/'+exType+'/'+expInfo['participant']+'/'+expName+'/'+results_fname)\n",
    "record_data.to_csv(fname, index = False)\n",
    "print('Trial Ended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "58aa2379f332903eb3651e9f882b0a5c29c64a76df7303b0e4bd881d920d6646"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
